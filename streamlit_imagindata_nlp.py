# -*- coding: utf-8 -*-
"""streamlit_imagindata NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uh7Xjg64-3E9POpa0zJkLTi9uzH_ykEm
"""

pip install --upgrade streamlit

pip install streamlit

import streamlit as st
import requests
import pandas as pd

#CHARGEMENT DES DATAFRAMES

df_actors = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_algo_actors")

df_actors

df_directors = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_algo_directors")

df_directors

df_prod = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_algo_prod")

df_prod

df_NLP = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_mainNLP")

df_NLP

pip show nltk

pip show nltk.corpus

pip show re

pip show string

pip show sklearn.feature_extraction.text

pip show nltk.stem.snowball

pip show sklearn.metrics.pairwise

pip show random

pip show requests

#VERSION AVEC LISTE DEROULANTE VF

import streamlit as st
import requests
import pandas as pd
import nltk
from nltk.corpus import stopwords
import re
import string
from sklearn.feature_extraction.text import CountVectorizer
from nltk.stem.snowball import SnowballStemmer
from sklearn.metrics.pairwise import cosine_similarity
import random



nltk.download('punkt')
nltk.download('stopwords')

def main():
    st.set_page_config(page_title="üé• App de Recommandation de films", page_icon=":üéûÔ∏è:", layout="wide", initial_sidebar_state="expanded")
    st.title("App de Recommandation de films")

    # Charger les DataFrames depuis l'URL
    df_actors = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_algo_actors")
    df_directors = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_algo_directors")
    df_NLP = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_mainNLP")
    df_prod = pd.read_csv("https://raw.githubusercontent.com/IMAGINEDATA1/APP/main/t_algo_prod")

    # Barre de recherche pour la recommandation
    search_option_mapping = {"Titre": "primaryTitle", "Acteur": "primaryName", "R√©alisateur": "primaryName", "Genre": "genres", "Ann√©e": "startYear", "Soci√©t√© de production": "prod_name"}
    search_option = st.selectbox("Choisir une option de recherche", list(search_option_mapping.keys()))
    user_input_film = None

    if search_option in search_option_mapping:
        column_name = search_option_mapping[search_option]
        default_value = df_actors[column_name].iloc[0] + df_directors[column_name].iloc[0] + df_prod[column_name].iloc[0] + df_NLP[column_name].iloc[0]
        user_input_film = st.text_input(f"Choisir un(e) {search_option.lower()}", default_value)

    if st.button("Rechercher"):
        if user_input_film:
            # Conversion en str des colonnes
            columns_to_convert = ['primaryTitle', 'overview', 'tagline', 'actors', 'directors', 'prod_name', 'tags_NLP']
            df_NLP[columns_to_convert] = df_NLP[columns_to_convert].astype(str)

            # Fonction nettoyage
            def clean(text):
                tokens = nltk.word_tokenize(text.lower())
                tokens_clean = []
                additional_stopwords = ["'s", "ca", "n't"]
                stopwordsenglish = set(stopwords.words('english') + additional_stopwords)

                for word in tokens:
                    word = word.strip(string.punctuation)
                    if word and word not in stopwordsenglish and not re.match(r'^\W+$', word):
                        tokens_clean.append(word)
                cleaned_text = ' '.join(tokens_clean)
                return cleaned_text

            df_NLP['tags_NLP'] = df_NLP['tags_NLP'].apply(clean)

            # Transforme un texte en vecteur sur la base du comptage de la fr√©quence de chaque mot.
            cv = CountVectorizer(stop_words='english')
            cv.fit_transform(df_NLP['tags_NLP']).toarray().shape
            vectors = cv.fit_transform(df_NLP['tags_NLP']).toarray()

            # Choix Stemming
            ps = SnowballStemmer("english")

            def stem(text):
                y = []
                for i in text.split():
                    y.append(ps.stem(i))
                return " ".join(y)

            df_NLP['tags_NLP'] = df_NLP['tags_NLP'].apply(stem)

            similarity = cosine_similarity(vectors)
            movies_list = sorted(list(enumerate(similarity[0])), reverse=True, key=lambda x: x[1])[1:6]

            # Affichage du choix de l'utilisateur
            display_user_choice(user_input_film, search_option, df_NLP)

            # Affichage des recommandations avec boutons
            display_recommandations(movies_list, df_NLP)

        else:
            st.warning("Aucun r√©sultat trouv√©.")

            # 4 films choisis al√©atoirement comme recommandations
            random_recos = random.sample(df_NLP['primaryTitle'].tolist(), 4)
            display_recommandations(random_recos, df_NLP)

# NLP Fonction pour filtrer le DataFrame en fonction de l'option de recherche

def display_user_choice(dataframes, search_option, user_input_film):
    filtered_dataframes = [df_NLP, df_actors, df_directors, df_prod]

    for df in dataframes:
        if search_option == "Acteur":
            selected_movie = filtered_dataframes.append(df_actors[df_actors['primaryName'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "R√©alisateur":
            selected_movie = filtered_dataframes.append(df_directors[df_directors['primaryName'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Titre":
            filtered_dataframes.append(df_NLP[df_NLP['primaryTitle'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Genre":
            filtered_dataframes.append(df_NLP[df_NLP['genres'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Ann√©e":
            filtered_dataframes.append(df_NLP[df_NLP['startYear'] == int(user_input_film)].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Soci√©t√© de production":
            filtered_dataframes.append(df_prod[df_prod['prod_name'] == user_input_film])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        else:
            filtered_dataframes.append(df)

    return display_user_choice



# Fonction pour Affichage des recommandations
# calcul recos
def recommend_similar_movies(keyword):
    # Recherche films avec mot-cle
    user_input_film = df_NLP[df_NLP['primaryTitle'].str.contains(keyword, case=False, na=False)]
    if not user_input_film.empty:
        # Obtenir indices films corresp.
        movie_indices = user_input_film.index
        user_movie_details = get_movie_details(movie_indices['tconst'])
        # Calcul similarite cosinus pour films corresp
        distances = np.median(similarity[movie_indices], axis=0)
        # Tri + obtenir indices des films reco
        sorted_indices = np.argsort(distances)[::-1]
        # S√©lection des 5 premiers indices
        num_recommendations = min(5, len(sorted_indices))
        movies_list = sorted_indices[1:num_recommendations + 1]
        user_movie_details = get_movie_details(movies_list['tconst'])

        # Affichage
        for i in user_movie_details:
            st.write(df_NLP.iloc[i].primaryTitle)
    else:
        st.write(f"Aucun film trouv√© avec le mot-cl√© '{keyword}'.")



def display_recommandations(random_recos, df_NLP):
    st.subheader("Autres films recommand√©s:")

    # Utiliser des colonnes pour afficher les recommandations en ligne
    cols = st.columns(len(random_recos))

    # Afficher les informations sur chaque recommandation
    for col, index in zip(cols, random_recos):
        movie_title = df_NLP.loc[index, 'primaryTitle']
        movie_details = get_movie_details(df_NLP.loc[index, 'tconst'])
        col.image(f"https://image.tmdb.org/t/p/w200/{movie_details.get('poster_path')}", width=150, use_column_width=False)
        col.button(movie_title, key=f"button_{index}", on_click=display_movie_popup, args=(movie_details,))


# Fonction pour obtenir les informations d'un film √† partir de l'API TMDb
def get_movie_details(movie_id):
    api_key = "db38952c66997974559ef641200fc25e"
    base_url = "https://api.themoviedb.org/3/movie/"
    endpoint = str(movie_id)
    url = f"{base_url}{endpoint}?api_key={api_key}&append_to_response=credits"

    response = requests.get(url)
    if response.status_code == 200:
        return response.json()
    else:
        return None

# Fonction pour afficher les d√©tails du film dans une fen√™tre pop-up
def display_movie_popup(movie_details):
    st.image(f"https://image.tmdb.org/t/p/w200/{movie_details.get('poster_path')}", width=150, use_column_width=False)
    st.markdown(f"**Titre:** {movie_details.get('title')}")
    st.markdown(f"**Tagline:** {movie_details.get('tagline')}")
    st.markdown(f"**Aper√ßu:** {movie_details.get('overview')}")
    st.write(f"**Note IMDb:** {movie_details.get('vote_average')}")
    st.write(f"**Nombre de votes:** {movie_details.get('vote_count')}")
    st.write(f"**Dur√©e:** {movie_details.get('runtime')} minutes")
    st.write(f"**Genre:** {', '.join([genre['name'] for genre in movie_details.get('genres', [])])}")
    st.write("**Acteurs:**")
    cast_members = movie_details.get('credits', {}).get('cast', [])[:3]
    for cast_member in cast_members:
        st.write(f"- {cast_member.get('name')}")
    st.write("**R√©alisateurs:**")
    crew_members = movie_details.get('credits', {}).get('crew', [])
    directors = [crew_member.get('name') for crew_member in crew_members if crew_member.get('job') == 'Director']
    for director in directors:
        st.write(f"- {director}")

# Fonction pour afficher les d√©tails du film √† partir de l'API TMDb
def display_movie_details(movie_details):
    if movie_details:
        st.image(f"https://image.tmdb.org/t/p/w200/{movie_details.get('poster_path')}", width=150, use_column_width=False)
        st.markdown(f"**Titre:** {movie_details.get('title')}")
        st.markdown(f"**Tagline:** {movie_details.get('tagline')}")
        st.markdown(f"**Aper√ßu:** {movie_details.get('overview')}")
        st.write(f"**Note IMDb:** {movie_details.get('vote_average')}")
        st.write(f"**Nombre de votes:** {movie_details.get('vote_count')}")
        st.write(f"**Dur√©e:** {movie_details.get('runtime')} minutes")
        st.write(f"**Genre:** {', '.join([genre['name'] for genre in movie_details.get('genres', [])])}")

        st.write("**Acteurs:**")
        cast_members = movie_details.get('credits', {}).get('cast', [])[:3]
        for cast_member in cast_members:
            st.write(f"- {cast_member.get('name')}")

        st.write("**R√©alisateurs:**")
        crew_members = movie_details.get('credits', {}).get('crew', [])
        directors = [crew_member.get('name') for crew_member in crew_members if crew_member.get('job') == 'Director']
        for director in directors:
            st.write(f"- {director}")
    else:
        st.info("Film non trouv√© ou erreur lors de la r√©cup√©ration des d√©tails.")

if __name__ == "__main__":
    main()

st.subheader("Bonne s√©ance ! üçøüçøüçø ")

# TEST NLP - Fonction pour Affichage du choix de l'utilisateur
def display_user_choice(dataframes, search_option, user_input_film):
    filtered_dataframes = [df_NLP, df_actors, df_directors, df_prod]

    for df in dataframes:
        if search_option == "Acteur":
            selected_movie = filtered_dataframes.append(df_actors[df_actors['primaryName'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "R√©alisateur":
            selected_movie = filtered_dataframes.append(df_directors[df_directors['primaryName'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Titre":
            filtered_dataframes.append(df_NLP[df_NLP['primaryTitle'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Genre":
            filtered_dataframes.append(df_NLP[df_NLP['genres'] == user_input_film].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Ann√©e":
            filtered_dataframes.append(df_NLP[df_NLP['startYear'] == int(user_input_film)].iloc[0])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        elif search_option == "Soci√©t√© de production":
            filtered_dataframes.append(df_prod[df_prod['prod_name'] == user_input_film])
            user_movie_details = get_movie_details(selected_movie['tconst'])

        else:
            filtered_dataframes.append(df)

    return filtered_dataframes

****************************************************

# TEST KNN - Fonction pour Affichage du choix de l'utilisateur
#def display_user_choice(user_input_film, search_option, df_KNN):
#    st.subheader("Votre choix:")
#    if not df_KNN.empty:
#        if search_option in ["Acteur", "R√©alisateur", "Titre"]:
#            selected_movie = df_KNN[df_KNN[search_option.lower()] == user_input_film].iloc[0]
#            user_movie_details = get_movie_details(selected_movie['tconst'])
#        elif search_option == "Genre":
#            selected_movie = df_KNN[df_KNN['genre'] == user_input_film].iloc[0]
#            user_movie_details = get_movie_details(selected_movie['tconst'])
#        elif search_option == "Ann√©e":
#            selected_movie = df_KNN[df_KNN['startYear'] == int(user_input_film)].iloc[0]
#            user_movie_details = get_movie_details(selected_movie['tconst'])
#        elif search_option == "Soci√©t√© de production":
#             selected_movie = df_KNN[df_KNN['prod_name'] == user_input_film].iloc[0]
#             user_movie_details = get_movie_details(selected_movie['tconst'])
#        else:
#            user_movie_details = None
#
#        if user_movie_details:
#            display_movie_details(user_movie_details)
#        else:
#            st.info("Film non trouv√© ou erreur lors de la r√©cup√©ration des d√©tails.")
#    else:
#        st.info("Aucun r√©sultat trouv√©.")

****************************************************

***** ALGO NLP A TESTER *****
import nltk
from nltk.corpus import stopwords
import re
import string
nltk.download('punkt')
nltk.download('stopwords')
# conversion en str des colonnes
columns_to_convert = ['primaryTitle', 'overview', 'tagline', 'actors', 'directors', 'prod_name', 'tags_NLP']
df_NLP[columns_to_convert] = df_NLP[columns_to_convert].astype(str)
# fonction nettoyage
def clean(text):
  tokens = nltk.word_tokenize(text.lower())
  tokens_clean = []
  additional_stopwords = ["'s", "ca", "n't"]
  stopwordsenglish = set(stopwords.words('english') + additional_stopwords)
  for word in tokens:
    word = word.strip(string.punctuation)
    if word and word not in stopwordsenglish and not re.match(r'^\W+$', word):
      tokens_clean.append(word)
  cleaned_text = ' '.join(tokens_clean)
  return cleaned_text
df_NLP['tags_NLP'] = df_NLP['tags_NLP'].apply(clean)
from sklearn.feature_extraction.text import CountVectorizer #transforme un texte en vecteur sur la base du comptage de la fr√©quence de chaque mot.
cv = CountVectorizer(stop_words= 'english')
cv.fit_transform(df_NLP['tags_NLP']).toarray().shape
vectors = cv.fit_transform(df_NLP['tags_NLP']).toarray()
# choix Stemming
import nltk
from nltk.stem.snowball import SnowballStemmer
ps = SnowballStemmer("english")
def stem(text):
   y=[]
   for i in text.split():
       y.append(ps.stem(i))
   return " ".join(y)
df_NLP['tags_NLP'] = df_NLP['tags_NLP'].apply(stem) (modifi√©)



# mesure de la similarit√© entre 2 vecteurs
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(vectors)
sorted(list(enumerate(similarity[0])), reverse = True, key= lambda x:x[1])[1:6]
import random
# calcul recos
def recommend_similar_movies(keyword):
    # Recherche films avec mot-cle
    matching_movies = df_NLP[df_NLP['primaryTitle'].str.contains(keyword, case=False, na=False)]
    if not matching_movies.empty:
        # Obtenir indices films corresp.
        movie_indices = matching_movies.index
        # Calcul similarite cosinus pour films corresp
        distances = np.median(similarity[movie_indices], axis=0)
        # Tri + obtenir  indices des films reco
        sorted_indices = np.argsort(distances)[::-1]
        # S√©lection des 5 premiers indices
        num_recommendations = min(5, len(sorted_indices))
        movies_list = sorted_indices[1:num_recommendations + 1]
        # Affichage
        for i in movies_list:
            print(df_NLP.iloc[i].primaryTitle)
    else:
        print(f"Aucun film trouv√© avec le mot-cl√© '{keyword}'.")